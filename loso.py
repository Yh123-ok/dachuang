import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, Subset
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, f1_score, accuracy_score
import numpy as np
import os
import scipy.io as sio

# ==========================================
# ğŸ› ï¸ æ¨¡å— 1: åŸºç¡€ç»„ä»¶ - æ®‹å·®åŠ¨æ€å›¾å±‚
# ==========================================
class ResDGFLayer(nn.Module):
    """
    æ ¸å¿ƒç»„ä»¶ï¼šåŠ¨æ€å›¾å·ç§¯ + æ®‹å·®è¿æ¥ + LayerNorm
    èƒ½å¤Ÿæ ¹æ®ç‰¹å¾å†…å®¹çš„ç›¸ä¼¼æ€§åŠ¨æ€æ„å»ºé‚»æ¥çŸ©é˜µã€‚
    """
    def __init__(self, d_model, num_heads=4):
        super().__init__()
        self.num_heads = num_heads
        # log_sigmas æ§åˆ¶é«˜æ–¯æ ¸çš„å®½åº¦ï¼Œè®¾ä¸ºå¯å­¦ä¹ å‚æ•°
        self.log_sigmas = nn.Parameter(torch.zeros(num_heads, 1, 1))
        self.proj = nn.Linear(d_model, d_model)
        self.norm = nn.LayerNorm(d_model)
        self.activation = nn.ELU()

    def forward(self, x):
        # x shape: [Batch, Nodes, Dim]
        b, n, d = x.size()
        
        # 1. è®¡ç®—èŠ‚ç‚¹é—´çš„æˆå¯¹æ¬§æ°è·ç¦»
        dist_sq = torch.cdist(x, x, p=2)**2 # [B, N, N]
        
        # 2. è®¡ç®—åŠ¨æ€é‚»æ¥çŸ©é˜µ (RBF Kernel)
        sigmas = torch.exp(self.log_sigmas) # ç¡®ä¿ sigma > 0
        # å¹¿æ’­æœºåˆ¶: [B, 1, N, N] / [H, 1, 1] -> [B, H, N, N]
        adjs = torch.exp(-dist_sq.unsqueeze(1) / (2 * sigmas.unsqueeze(0)**2 + 1e-6))
        
        # 3. å¤šå¤´å¹³å‡èšåˆ
        adj_final = adjs.mean(dim=1) # [B, N, N]
        
        # 4. å›¾å·ç§¯æ“ä½œ
        out = torch.matmul(adj_final, x) # Aggregation
        out = self.proj(out)             # Update
        
        # 5. æ®‹å·®è¿æ¥ä¸å½’ä¸€åŒ– (å…³é”®æ­¥éª¤ï¼Œé˜²æ­¢æ·±å±‚ç½‘ç»œé€€åŒ–)
        return self.norm(self.activation(out) + x)

# ==========================================
# ğŸ› ï¸ æ¨¡å— 2: æ·±å±‚ GNN å †å å— (Deep Stack)
# ==========================================
class DeepGNNBlock(nn.Module):
    """
    å †å å¤šä¸ª ResDGFLayerï¼Œå¢åŠ æ„Ÿå—é‡ï¼Œæ•æ‰é«˜é˜¶å…³ç³»ã€‚
    """
    def __init__(self, d_model, layers=3, num_heads=4):
        super().__init__()
        self.layers = nn.ModuleList([
            ResDGFLayer(d_model, num_heads) for _ in range(layers)
        ])
        
    def forward(self, x):
        for layer in self.layers:
            x = layer(x)
        return x

# ==========================================
# ğŸ§  æ¨¡å— 3: Deep-Res-MT-DGF-GNN æ¨¡å‹ä¸»ä½“
# ==========================================
class Deep_MT_DGF_GNN(nn.Module):
    def __init__(self, hidden_dim=64):
        super().__init__()
        
        # --- åˆ†æ”¯ A: CNN (å¤„ç†è„‘ç”µåœ°å½¢å›¾ 5x32x32) ---
        self.cnn_net = nn.Sequential(
            nn.Conv2d(5, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ELU(),
            nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ELU(),
            nn.AdaptiveAvgPool2d((2, 2)), 
            nn.Flatten() # 32*2*2 = 128
        )
        self.cnn_proj = nn.Linear(128, hidden_dim)

        # --- åˆ†æ”¯ B: Deep GNN (å¤„ç†ç”µæç»Ÿè®¡ç‰¹å¾ 32x7) ---
        self.gnn_mapping = nn.Linear(7, hidden_dim)
        # ğŸŒŸ ä½¿ç”¨ 3 å±‚æ·±åº¦çš„ GNN æå– 32 ä¸ªç”µæé—´çš„å¤æ‚ç©ºé—´å…³ç³»
        self.deep_gnn = DeepGNNBlock(d_model=hidden_dim, layers=3, num_heads=4)

        # --- åˆ†æ”¯ C: MLP (å¤„ç†å¤–å‘¨ç”Ÿç†ç‰¹å¾ 55ç»´) ---
        self.peri_net = nn.Sequential(
            nn.Linear(55, hidden_dim), 
            nn.LayerNorm(hidden_dim), 
            nn.ELU()
        )

        # --- èåˆæ¨¡å—: è·¨æ¨¡æ€åŠ¨æ€å›¾ ---
        # å°† CNN, GNN, Peri ä¸‰ä¸ªç‰¹å¾å‘é‡çœ‹ä½œå›¾ä¸­çš„ 3 ä¸ªèŠ‚ç‚¹è¿›è¡Œèåˆ
        self.fusion_layer = ResDGFLayer(hidden_dim, num_heads=8)
        
        # --- å¤šä»»åŠ¡è¾“å‡ºå¤´ (MTL Heads) ---
        # å…±äº«ç‰¹å¾ -> ç‹¬ç«‹é¢„æµ‹
        combined_dim = hidden_dim * 3
        self.v_head = nn.Sequential(nn.Linear(combined_dim, 64), nn.ELU(), nn.Linear(64, 2))
        self.a_head = nn.Sequential(nn.Linear(combined_dim, 64), nn.ELU(), nn.Linear(64, 2))
        
        # --- è‡ªåŠ¨æƒé‡å‚æ•° (Uncertainty Weights) ---
        # log_vars = log(sigma^2)ï¼Œç”¨äºå¹³è¡¡å¤šä»»åŠ¡ Loss
        self.log_vars = nn.Parameter(torch.zeros(2)) 

    def forward(self, maps, stats, peri):
        # 1. ç‰¹å¾æå–
        # CNN Branch
        h_cnn = self.cnn_proj(self.cnn_net(maps)).unsqueeze(1) # [B, 1, H]
        
        # Deep GNN Branch
        gnn_in = self.gnn_mapping(stats) 
        h_gnn_nodes = self.deep_gnn(gnn_in) # [B, 32, H] (ç»è¿‡3å±‚äº¤äº’)
        h_gnn = h_gnn_nodes.mean(dim=1, keepdim=True) # å…¨å±€èšåˆ [B, 1, H]
        
        # Peri Branch
        h_peri = self.peri_net(peri).unsqueeze(1) # [B, 1, H]

        # 2. åŠ¨æ€èåˆ (Heterogeneous Graph)
        # æ‹¼æ¥ä¸‰ä¸ªæ¨¡æ€èŠ‚ç‚¹: [B, 3, H]
        combined = torch.cat([h_cnn, h_gnn, h_peri], dim=1) 
        # å­¦ä¹ æ¨¡æ€é—´çš„æ³¨æ„åŠ›
        fused = self.fusion_layer(combined)
        
        # 3. å±•å¹³å¹¶åˆ†ç±»
        flat_feat = fused.view(fused.size(0), -1) # [B, 3*H]
        return self.v_head(flat_feat), self.a_head(flat_feat)

# ==========================================
# ğŸ’¾ æ¨¡å— 4: æ•°æ®åŠ è½½ä¸æ ‡ç­¾å¯¹é½
# ==========================================
class DeapLOSODataset(Dataset):
    def __init__(self, npz_dir, raw_mat_dir):
        self.npz_dir = npz_dir
        self.raw_mat_dir = raw_mat_dir
        self.file_list = sorted([f for f in os.listdir(npz_dir) if f.endswith('.npz')])
        self.samples_per_subject = 600  # æ¯ä¸ªè¢«è¯•å›ºå®šçš„æ ·æœ¬æ•° (40 trials * 15 samples)
        
        self.v_labels_list = [] # æŒ‰è¢«è¯•å­˜æ”¾ï¼Œæ–¹ä¾¿æå–
        self.a_labels_list = []
        
        print(f"ğŸ“¦ æ­£åœ¨åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨... å…±æ£€æµ‹åˆ° {len(self.file_list)} ä¸ªè¢«è¯•")
        
        for f_name in self.file_list:
            subj_id = f_name[:3] 
            mat_path = os.path.join(raw_mat_dir, f"{subj_id}.mat")
            
            if not os.path.exists(mat_path):
                raise FileNotFoundError(f"æœªæ‰¾åˆ°æ ‡ç­¾æ–‡ä»¶: {mat_path}")
                
            raw_labels = sio.loadmat(mat_path)['labels']
            # äºŒå€¼åŒ–
            v_bin = (raw_labels[:, 0] > 5).astype(np.int64)
            a_bin = (raw_labels[:, 1] > 5).astype(np.int64)
            
            # æ‰©å±•å¹¶å­˜å…¥åˆ—è¡¨
            self.v_labels_list.append(np.repeat(v_bin, 15))
            self.a_labels_list.append(np.repeat(a_bin, 15))
            
        # å±•å¹³ä»¥ä¾¿æ”¯æŒå¸¸è§„ç´¢å¼•è°ƒç”¨ __getitem__
        self.all_v = np.concatenate(self.v_labels_list)
        self.all_a = np.concatenate(self.a_labels_list)

    def __len__(self):
        return len(self.all_v)

    def get_train_indices(self, test_subj_idx):
        """æ ¸å¿ƒï¼šè®¡ç®—é™¤äº†ç¬¬ test_subj_idx ä¸ªè¢«è¯•å¤–çš„æ‰€æœ‰ç´¢å¼•"""
        all_indices = np.arange(len(self))
        test_start = test_subj_idx * self.samples_per_subject
        test_end = (test_subj_idx + 1) * self.samples_per_subject
        # å‰”é™¤æµ‹è¯•é›†ç´¢å¼•
        train_mask = np.ones(len(self), dtype=bool)
        train_mask[test_start:test_end] = False
        return all_indices[train_mask].tolist()

    def get_subject_data(self, subj_idx):
        """æ ¸å¿ƒï¼šä¸€æ¬¡æ€§è·å–æŸä¸ªè¢«è¯•çš„å…¨éƒ¨ Tensorï¼Œé¿å…æµ‹è¯•æ—¶åå¤ IO"""
        file_path = os.path.join(self.npz_dir, self.file_list[subj_idx])
        with np.load(file_path) as data:
            m = torch.from_numpy(data['eeg_allband_feature_map']).float()
            s = torch.from_numpy(data['eeg_en_stat']).view(-1, 32, 7).float()
            p = torch.from_numpy(data['peri_feature']).float()
        
        v = torch.from_numpy(self.v_labels_list[subj_idx]).long()
        a = torch.from_numpy(self.a_labels_list[subj_idx]).long()
        return m, s, p, v, a

    def __getitem__(self, idx):
        subj_idx = idx // self.samples_per_subject
        inner_idx = idx % self.samples_per_subject
        file_path = os.path.join(self.npz_dir, self.file_list[subj_idx])
        
        with np.load(file_path) as data:
            maps = torch.from_numpy(data['eeg_allband_feature_map'][inner_idx]).float()
            stats = torch.from_numpy(data['eeg_en_stat'][inner_idx]).view(32, 7).float()
            peri = torch.from_numpy(data['peri_feature'][inner_idx]).float()
            
        return maps, stats, peri, self.all_v[idx], self.all_a[idx]
# ==========================================
# ğŸš€ æ¨¡å— 5: è®­ç»ƒå¼•æ“ä¸è¯„ä¼°
# ==========================================
def train_deep_mt_dgf_loso():
    # --- é…ç½®åŒºåŸŸ ---
    NPZ_PATH = r'D:\Users\cyz\dc\222'
    RAW_PATH = r'E:\BaiduNetdiskDownload\DEAP\data_preprocessed_matlab'
    BATCH_SIZE = 64
    EPOCHS = 10  # LOSO å»ºè®® 10-15 Epochï¼Œä¿æŒè¢«è¯•é—´æ³›åŒ–æ€§
    LR = 0.0005
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # 1. å‡†å¤‡æ•°æ®é›†
    dataset = DeapLOSODataset(NPZ_PATH, RAW_PATH)
    num_subjects = len(dataset.file_list)
    all_subject_f1 = []

    print(f"\nâš¡ å¯åŠ¨ LOSO éªŒè¯æµç¨‹ | è¢«è¯•æ€»æ•°: {num_subjects} | è®¾å¤‡: {DEVICE}")

    # 2. å¤–éƒ¨å¾ªç¯ï¼šLeave-One-Subject-Out
    for test_subj_idx in range(num_subjects):
        subj_name = dataset.file_list[test_subj_idx][:3]
        print(f"\n>>> [Fold {test_subj_idx+1}/{num_subjects}] æµ‹è¯•è¢«è¯•: {subj_name}")
        
        # åˆ’åˆ†ç´¢å¼•å¹¶åˆ›å»ºè®­ç»ƒ Loader
        train_idx = dataset.get_train_indices(test_subj_idx)
        train_loader = DataLoader(Subset(dataset, train_idx), batch_size=BATCH_SIZE, shuffle=True)
        
        # é¢„åŠ è½½æµ‹è¯•è¢«è¯•æ•°æ®åˆ°æ˜¾å­˜ (åŠ é€ŸéªŒè¯)
        tm, ts, tp, tlv, tla = dataset.get_subject_data(test_subj_idx)
        tm, ts, tp = tm.to(DEVICE), ts.to(DEVICE), tp.to(DEVICE)

        # åˆå§‹åŒ–æ¨¡å‹
        model = Deep_MT_DGF_GNN(hidden_dim=64).to(DEVICE)
        optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-3)

        # 3. å†…éƒ¨å¾ªç¯ï¼šè®­ç»ƒ
        for epoch in range(1, EPOCHS + 1):
            model.train()
            for maps, stats, peri, lv, la in train_loader:
                maps, stats, peri = maps.to(DEVICE), stats.to(DEVICE), peri.to(DEVICE)
                lv, la = lv.to(DEVICE), la.to(DEVICE)
                
                ov, oa = model(maps, stats, peri)
                
                # å¤šä»»åŠ¡ Loss è®¡ç®—
                loss_v = F.cross_entropy(ov, lv)
                loss_a = F.cross_entropy(oa, la)
                
                # è‡ªåŠ¨æƒé‡æ›´æ–°é€»è¾‘
                combined_loss = (loss_v * torch.exp(-model.log_vars[0]) + model.log_vars[0]) + \
                                (loss_a * torch.exp(-model.log_vars[1]) + model.log_vars[1])
                
                optimizer.zero_grad()
                combined_loss.backward()
                optimizer.step()

        # 4. è¯„ä¼°é˜¶æ®µ (é’ˆå¯¹å½“å‰æµ‹è¯•è¢«è¯•)
        model.eval()
        with torch.no_grad():
            # é¢„æµ‹å¹¶æå–èåˆæƒé‡
            ov, oa, weights = model(tm, ts, tp, return_weights=True)
            
            # è®¡ç®— F1 æŒ‡æ ‡
            pred_v = ov.argmax(dim=1).cpu().numpy()
            pred_a = oa.argmax(dim=1).cpu().numpy()
            f1_v = f1_score(tlv.numpy(), pred_v, average='macro')
            f1_a = f1_score(tla.numpy(), pred_a, average='macro')
            
            # è·¨æ¨¡æ€é‡è¦æ€§åˆ†æ
            # weights [Batch, 3, 3] -> å‡å€¼ -> å½’ä¸€åŒ–
            imp = weights.mean(dim=0).sum(dim=0).cpu().numpy()
            imp /= imp.sum()
            
            print(f"   Done. Valence F1: {f1_v:.4f} | Arousal F1: {f1_a:.4f}")
            print(f"   ğŸ§  æ¨¡æ€è´¡çŒ®åº¦: EEG-CNN: {imp[0]:.1%} | EEG-GNN: {imp[1]:.1%} | Peri: {imp[2]:.1%}")
            
            all_subject_f1.append((f1_v + f1_a) / 2)
            
        # é‡Šæ”¾èµ„æºé˜²æ­¢ OOM
        del model, optimizer
        torch.cuda.empty_cache()

    # 5. æ‰“å°å…¨å±€å®éªŒç»“è®º
    print("\n" + "=".center(40, "="))
    print(f"ğŸ† LOSO å®éªŒåœ†æ»¡ç»“æŸ")
    print(f"å¹³å‡æ€»ä½“ F1: {np.mean(all_subject_f1):.4f}")
    print("=".center(40, "="))
if __name__ == "__main__":
    train_deep_mt_dgf_loso()